{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccaaaec0-6abd-43e1-8587-65461963ee2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ./20230831_060603_pr_sharings.json\n",
      "Processing file: ./20230831_061759_issue_sharings.json\n",
      "Processing file: ./20230831_061926_discussion_sharings.json\n",
      "Processing file: ./20230831_063412_commit_sharings.json\n",
      "Processing file: ./20230831_072722_file_sharings.json\n",
      "Processing file: ./20230831_073827_hn_sharings.json\n",
      "Data successfully saved to merged_conversations.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Define the function to extract conversations from the ChatGPT sharing data\n",
    "def extract_conversations(chatgpt_sharing):\n",
    "    \"\"\"\n",
    "    Extract detailed ChatGPT conversations from the given sharing data.\n",
    "\n",
    "    Parameters:\n",
    "    chatgpt_sharing (list): A list containing ChatGPT sharing entries.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries, each representing a conversation with detailed information.\n",
    "    \"\"\"\n",
    "    if isinstance(chatgpt_sharing, list):\n",
    "        conversations = []\n",
    "        for entry in chatgpt_sharing:\n",
    "            # Check if the entry contains the 'Conversations' field\n",
    "            if 'Conversations' in entry:\n",
    "                for convo in entry['Conversations']:\n",
    "                    conversations.append({\n",
    "                        \"Prompt\": convo.get(\"Prompt\"),\n",
    "                        \"Answer\": convo.get(\"Answer\"),\n",
    "                        \"ListOfCode\": convo.get(\"ListOfCode\"),\n",
    "                        \"ChatgptURL\": entry.get(\"URL\"),\n",
    "                        \"DateOfConversation\": entry.get(\"DateOfConversation\"),\n",
    "                        \"Model\": entry.get(\"Model\"),\n",
    "                        \"NumberOfPrompts\": entry.get(\"NumberOfPrompts\"),\n",
    "                        \"TokensOfPrompts\": entry.get(\"TokensOfPrompts\"),\n",
    "                        \"TokensOfAnswers\": entry.get(\"TokensOfAnswers\"),\n",
    "                    })\n",
    "        return conversations\n",
    "    return None\n",
    "\n",
    "# Define the function to process a single JSON file\n",
    "def process_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Process a single JSON file to extract and flatten ChatGPT conversation data.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the processed data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the JSON file\n",
    "        df = pd.read_json(file_path)\n",
    "        # Flatten nested data in the 'Sources' column\n",
    "        df = pd.json_normalize(df['Sources'])\n",
    "    except (ValueError, KeyError) as e:\n",
    "        print(f\"Failed to load file {file_path}: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame to avoid interruption\n",
    "\n",
    "    # Select relevant columns for processing\n",
    "    basic_columns = ['Type', 'URL', 'Author', 'Title', 'Body', 'CreatedAt', 'State', 'ChatgptSharing']\n",
    "    basic_columns_in_df = [col for col in basic_columns if col in df.columns]\n",
    "    basic_df = df[basic_columns_in_df]\n",
    "\n",
    "    # Extract and flatten conversation data\n",
    "    conversation_data = []\n",
    "    for _, row in basic_df.iterrows():\n",
    "        chatgpt_sharing = row.get('ChatgptSharing', None)\n",
    "        conversations = extract_conversations(chatgpt_sharing)\n",
    "        if conversations:\n",
    "            for convo in conversations:\n",
    "                conversation_data.append({\n",
    "                    \"SourceType\": row.get('Type', None),         # Source type\n",
    "                    \"SourceURL\": row.get('URL', None),           # Original source URL\n",
    "                    \"SourceAuthor\": row.get('Author', None),     # Original author\n",
    "                    \"SourceTitle\": row.get('Title', \"Unknown\"),  # Default title if missing\n",
    "                    **convo,                                     # ChatGPT conversation details\n",
    "                })\n",
    "    return pd.DataFrame(conversation_data)\n",
    "\n",
    "# Process all JSON files in the specified folder\n",
    "folder_path = \"./\"  # Path to the folder containing JSON files\n",
    "all_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "\n",
    "# Initialize an empty DataFrame to hold all conversations\n",
    "all_conversations = pd.DataFrame()\n",
    "\n",
    "# Process each file and append its data to the combined DataFrame\n",
    "for file in all_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    file_data = process_json_file(file_path)\n",
    "    if not file_data.empty:\n",
    "        all_conversations = pd.concat([all_conversations, file_data], ignore_index=True)\n",
    "\n",
    "# Check if there is any data to save\n",
    "if not all_conversations.empty:\n",
    "    # Save the merged data to a CSV file\n",
    "    output_csv_path = \"merged_conversations.csv\"\n",
    "    all_conversations.to_csv(output_csv_path, index=False, encoding='utf-8-sig')  # UTF-8-SIG supports non-ASCII characters\n",
    "    print(f\"Data successfully saved to {output_csv_path}\")\n",
    "else:\n",
    "    print(\"No valid data was processed. No output file was generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcfbe64-d6b7-42b2-ae78-82fffa6c0cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
